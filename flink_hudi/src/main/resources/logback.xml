<?xml version="1.0" encoding="UTF-8"?>
<!--
scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。
scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒当scan为true时，此属性生效。默认的时间间隔为1分钟。
debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。
参考文献：https://blog.csdn.net/HuanBuXingDeXingXing/article/details/115355304
-->
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <contextName>logback</contextName>

    <!-- 定义日志的根目录 -->
    <property name="log.path" value="${user.dir}/faaslog"/>
    <!--输出到控制台-->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level traceId= %X{traceId} [%class:%line] - %m %n</pattern>
        </encoder>
    </appender>

    <!--按天生成日志-->
    <appender name="logFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <Prudent>true</Prudent>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 滚动分割保存日志文件名称定义 -->
            <FileNamePattern>
                ${log.path}/%d{yyyy-MM-dd}/%d{yyyy-MM-dd}-%i.log
            </FileNamePattern>
            <!-- 日志文件保留天数，超过默认删除 -->
            <MaxHistory>365</MaxHistory>
            <!-- 文件大小分割，超过配置大小就建当天新的日志文件 -->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>10MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!--日志文档输出格式-->
        <layout class="ch.qos.logback.classic.PatternLayout">
            <Pattern>
                %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level traceId= %X{traceId} [%class:%line] - %m %n
            </Pattern>
        </layout>
    </appender>

    <!-- mybatis日志打印 -->
    <logger name="com.mybatis" level="error"/>
    <logger name="com.mybatis.common.jdbc.SimpleDataSource" level="error"/>
    <logger name="com.mybatis.common.jdbc.ScriptRunner" level="error"/>
    <logger name="com.mybatis.sqlmap.engine.impl.SqlMapClientDelegate"
            level="error"/>

    <logger name="java.sql.Connection" level="error"/>
    <logger name="java.sql.Statement" level="error"/>
    <logger name="java.sql.PreparedStatement" level="error"/>
    <Logger name="com.zaxxer.hikari" level="error"/>

    <logger name="org.apache.hadoop.fs.s3a.S3AInputStream" level="ERROR" />

    <!--<Logger name="org.apache.hadoop.fs" level="debug"/>
    <Logger name="org.apache.iceberg" level="debug"/>
    <Logger name="com.amazonaws" level="debug"/>-->

    <root level="info">
        <appender-ref ref="console"/>
        <appender-ref ref="logFile"/>
    </root>

</configuration>
